<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DCVLR: Data Curation for Vision Language Reasoning - NeurIPS 2025 Competition</title>
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="Join the DCVLR NeurIPS 2025 Competition focused on advancing visual reasoning capabilities in vision-language models through high-quality data curation. GPU credits, monetary prizes, and co-authorship opportunities.">
    <meta name="keywords" content="DCVLR, NeurIPS 2025, vision-language models, data curation, visual reasoning, machine learning competition, AI competition, computer vision, natural language processing">
    <meta name="author" content="DCVLR Competition Organizing Team">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://dcvlr-neurips.github.io/dcvlr-neurips/">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://dcvlr-neurips.github.io/dcvlr-neurips/">
    <meta property="og:title" content="DCVLR: Data Curation for Vision Language Reasoning - NeurIPS 2025 Competition">
    <meta property="og:description" content="Join the DCVLR NeurIPS 2025 Competition. Advance visual reasoning in VLMs through data curation. GPU credits and monetary prizes.">
    <meta property="og:image" content="https://dcvlr-neurips.github.io/dcvlr-neurips/images/og-image.jpg">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://dcvlr-neurips.github.io/dcvlr-neurips/">
    <meta property="twitter:title" content="DCVLR: NeurIPS 2025 Competition">
    <meta property="twitter:description" content="Join the DCVLR competition to advance visual reasoning in vision-language models. GPU credits and prizes.">
    <meta property="twitter:image" content="https://dcvlr-neurips.github.io/dcvlr-neurips/images/twitter-card.jpg">
    <meta property="twitter:site" content="@DCVLR_NeurIPS">
    
    <!-- Additional Meta Tags -->
    <meta name="theme-color" content="#2563eb">
    <meta name="application-name" content="DCVLR Competition">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    
    <!-- Structured Data for Event -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Event",
      "name": "DCVLR: Data Curation for Vision Language Reasoning Competition",
      "description": "A NeurIPS 2025 Competition focused on advancing visual reasoning capabilities in vision-language models through high-quality data curation",
      "startDate": "2025-07-01",
      "endDate": "2025-12-15",
      "eventStatus": "https://schema.org/EventScheduled",
      "eventAttendanceMode": "https://schema.org/OnlineEventAttendanceMode",
      "location": {
        "@type": "VirtualLocation",
        "url": "https://dcvlr-neurips.github.io/dcvlr-neurips/"
      },
      "organizer": {
        "@type": "Organization",
        "name": "DCVLR Competition Team",
        "url": "https://dcvlr-neurips.github.io/dcvlr-neurips/"
      },
      "sponsor": [
        {
          "@type": "Organization",
          "name": "NeurIPS"
        },
        {
          "@type": "Organization",
          "name": "Lambda Labs"
        },
        {
          "@type": "Organization",
          "name": "Oumi.ai"
        }
      ],
      "offers": {
        "@type": "Offer",
        "name": "Competition Registration",
        "price": "0",
        "priceCurrency": "USD",
        "availability": "https://schema.org/InStock",
        "url": "https://dcvlr-neurips.github.io/dcvlr-neurips/register",
        "validFrom": "2025-07-01"
      }
    }
    </script>
    <link rel="stylesheet" href="static/css/styles.css">
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LRCL2NG8LH"></script>
</head>
<body>
    <!-- Password Protection Overlay -->
    <div id="password-overlay" class="password-overlay">
        <div class="password-container">
            <div class="password-header">
                <h2>DCVLR Competition Access</h2>
                <p>Please enter the password to access the competition page</p>
            </div>
            <form id="password-form" class="password-form">
                <input type="password" id="password-input" placeholder="Enter password" required>
                <button type="submit">Access Competition</button>
                <div id="password-error" class="password-error" style="display: none;">
                    Incorrect password. Please try again.
                </div>
            </form>
        </div>
    </div>

    <!-- Main Content (hidden by default) -->
    <div id="main-content" class="main-content" style="display: none;">
    <header>
        <div class="container header-content">
                            <div class="logo">Data Curation for<br>Vision Language Reasoning</div>
            <nav>
                <ul>
                    <li><a href="#overview">Overview</a></li>
                    <li><a href="#resources">Resources</a></li>
                    <li><a href="#prizes">Prizes</a></li>
                    <li><a href="#team">Team</a></li>
                    <li><a href="#faq">FAQ</a></li>
                    <li><a href="#contact">Contact</a></li>
                    <li><a href="https://github.com/oumi-ai/oumi/tree/main/configs/projects/dcvlr" target="_blank" rel="noopener" class="github-link" aria-label="GitHub Repository">
                        <svg width="28" height="28" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                        </svg>
                    </a></li>
                    <li><a href="https://oumi-ai.typeform.com/to/LnYoisi5" class="cta-button" target="_blank" rel="noopener" onclick="trackButtonClick('header_signup', 'registration')">Sign Up</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <section class="hero">
        <div class="container">
            <h1>DCVLR: Data Curation for Vision Language Reasoning</h1>
            <p>A <a href="https://neurips.cc/" target="_blank" rel="noopener">NeurIPS 2025</a> Competition advancing the science of data curation for vision-language reasoning.</p>
            <div class="hero-actions">
                <a href="https://oumi-ai.typeform.com/to/LnYoisi5" class="cta-button" target="_blank" rel="noopener" onclick="trackButtonClick('hero_signup', 'registration')">Join the Research Challenge</a>
                <p class="subscription-note">Subscribe to receive competition updates, tips, and important announcements</p>
            </div>
        </div>
    </section>

    <section class="competition-overview" id="overview">
        <div class="container">
            <div class="section-title">
                <h2>Overview</h2>
                <p>DCVLR is the first open-data, open-models, open-source competition for data curation in vision-language reasoning, and will be hosted at <a href="https://neurips.cc/" target="_blank" rel="noopener">NeurIPS 2025</a></p> 
            </div>
            <div class="details-grid">
                <div class="detail-card">
                    <h3>üåü Open Science</h3>
                    <p>Winning methods, datasets, and teams will be published and promoted to advance the field. Students can apply for free compute from Lambda Labs, reducing barriers to entry and making cutting-edge research accessible to everyone, everywhere.</p>
                </div>
                <div class="detail-card">
                    <h3>üéØ Challenge</h3>
                    <p>Participants can leverage any source datasets to curate high-quality instruction-tuning datasets (1K or 10K examples). Participant are encouraged to explore diverse curation strategies, from synthetic data generation to subset selection. Submissions will be evaluated by fine-tuning an undisclosed, open-source vision-language model on the curated data and measuring performance across a wide variety of benchmarks.</p>
                </div>
                <div class="detail-card">
                    <h3>üî¨ Research Impact</h3>
                    <p>What properties of training data drive reasoning capabilities in vision-language models? By isolating data curation as the primary experimental variable, participants will generate novel insights into the relationship between data characteristics and model performance‚Äîcontributing to the emerging science of data-centric AI.</p>
                </div>
            </div>
        </div>
    </section>

    <section class="eligibility" id="eligibility">
        <div class="container">
            <div class="section-title">
                <h2>Eligibility & Requirements</h2>
                <p>Who can participate and what you need to know</p>
            </div>
            <div class="eligibility-grid">
                <div class="eligibility-card">
                    <h3>üåç Who Can Participate</h3>
                    <ul>
                        <li>Open to individuals and teams worldwide</li>
                        <li>Students, researchers, and industry professionals welcome</li>
                        <li>Teams can have up to 5 members</li>
                        <li>No prior competition experience required</li>
                        <li>Participants from all backgrounds encouraged</li>
                    </ul>
                </div>
                <div class="eligibility-card">
                    <h3>üìã Competition Rules</h3>
                    <ul>
                        <li>Can use any datasets for training data curation</li>
                        <li>Maximum 3 final submissions per team</li>
                        <li>Code must be open-sourced after competition</li>
                    </ul>
                </div>
                <div class="eligibility-card">
                    <h3>üö´ Restrictions</h3>
                    <ul>
                        <li>One account per participant/team</li>
                        <li>Must follow ethical data usage guidelines</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <section class="timeline" id="timeline">
        <div class="container">
            <div class="section-title">
                <h2>Key Dates</h2>
                <p>Key dates and milestones for the DCVLR competition</p>
            </div>
            <div class="timeline-container">
                <div class="timeline-item">
                    <div class="timeline-date">June 11, 2025</div>
                    <div class="timeline-content">
                        <h3>Release of Competition Materials</h3>
                        <p>Competition website and starter kit (data, code, baselines) available for download.</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">July 1, 2025</div>
                    <div class="timeline-content">
                        <h3>Submission Portal Opens</h3>
                        <p>Participants can begin submitting their curated datasets for evaluation.</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">October 1, 2025</div>
                    <div class="timeline-content">
                        <h3>Final Submission Deadline</h3>
                        <p>Last day to submit curated datasets for the competition.</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">November 1, 2025</div>
                    <div class="timeline-content">
                        <h3>Results Announced</h3>
                        <p>Leaderboard released with final results.</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">December 2025</div>
                    <div class="timeline-content">
                                            <h3><a href="https://neurips.cc/" target="_blank" rel="noopener">NeurIPS</a> 2025</h3>
                    <p>Presentation of results and awards at the <a href="https://neurips.cc/" target="_blank" rel="noopener">NeurIPS</a> conference.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="resources" id="resources">
        <div class="container">
            <div class="section-title">
                <h2>Competition Resources</h2>
                <p>Everything you need to participate in the DCVLR competition</p>
            </div>
            <div class="resources-grid">
                <div class="resource-card">
                    <div class="resource-icon">üìä</div>
                    <h3>Starter Kit</h3>
                    <p>Comprehensive starter kit with example datasets, training scripts, and best practices to help participants get started.</p>
                    <a href="https://huggingface.co/datasets/oumi-ai/dcvlr-starter-kit" target="_blank" rel="noopener" onclick="trackResourceAccess('starter_kit', 'dataset')">Access Starter Kit</a>
                </div>
                <div class="resource-card">
                    <div class="resource-icon">üíª</div>
                    <h3>Training Scripts</h3>
                    <p>Starting scripts for fine-tuning multiple vision-language models on your curated datasets.</p>
                    <a href="https://github.com/oumi-ai/oumi/tree/main/configs/projects/dcvlr" target="_blank" rel="noopener" onclick="trackResourceAccess('training_scripts', 'code')">View Scripts</a>
                </div>
                <div class="resource-card">
                    <div class="resource-icon">üß™</div>
                    <h3>Evaluation Code</h3>
                    <p>Scripts to evaluate model outputs on diverse benchmark development sets for local testing.</p>
                    <a href="https://github.com/oumi-ai/oumi/tree/main/configs/projects/dcvlr" target="_blank" rel="noopener" onclick="trackResourceAccess('evaluation_code', 'code')">Get Code</a>
                </div>
                <div class="resource-card">
                    <div class="resource-icon">üìù</div>
                    <h3>Baseline Submissions</h3>
                    <p>Reference implementations and baseline approaches for data curation and model training.</p>
                    <a href="https://github.com/oumi-ai/oumi/tree/main/configs/projects/dcvlr" target="_blank" rel="noopener" onclick="trackResourceAccess('baseline_submissions', 'code')">View Baselines</a>
                </div>
                <div class="resource-card">
                    <div class="resource-icon">‚òÅÔ∏è</div>
                    <h3>Compute Resources</h3>
                    <p>GPU credits from our compute sponsor Lambda Labs for first participants.</p>
                    <a href="https://oumi-ai.typeform.com/to/OGPuRt6Us" target="_blank" rel="noopener" onclick="trackResourceAccess('gpu_credits', 'compute')">Apply for Credits</a>
                </div>
                <div class="resource-card">
                    <div class="resource-icon">üìö</div>
                    <h3>Documentation</h3>
                    <p>Complete guides and tutorials to help you get started.</p>
                    <a href="https://docs.dcvlr-neurips.org/" target="_blank" rel="noopener" onclick="trackResourceAccess('documentation', 'docs')">View Documentation</a>
                </div>
            </div>
        </div>
    </section>

    <section class="prizes" id="prizes">
        <div class="container">
            <div class="section-title">
                <h2>Prizes</h2>
                <p>Recognizing excellence in data curation for vision-language reasoning</p>
            </div>
            <div class="prize-container">
                <div class="prize-tier gold">
                    <div class="prize-icon">ü•á</div>
                    <h3>First Place</h3>
                    <div class="prize-amount">$2,500 USD</div>
                    <ul class="prize-benefits">
                        <li>Podium presentation at NeurIPS 2025</li>
                        <li>Co-authorship on competition paper</li>
                        <li>$1,000 additional GPU credits</li>
                        <li>Featured team spotlight</li>
                    </ul>
                </div>
                <div class="prize-tier silver">
                    <div class="prize-icon">ü•à</div>
                    <h3>Second Place</h3>
                    <div class="prize-amount">$1,000 USD</div>
                    <ul class="prize-benefits">
                        <li>Podium presentation at NeurIPS 2025</li>
                        <li>Co-authorship on competition paper</li>
                        <li>$750 additional GPU credits</li>
                        <li>Featured team spotlight</li>
                    </ul>
                </div>
                <div class="prize-tier bronze">
                    <div class="prize-icon">ü•â</div>
                    <h3>Third Place</h3>
                    <div class="prize-amount">$500 USD</div>
                    <ul class="prize-benefits">
                        <li>Podium presentation at NeurIPS 2025</li>
                        <li>Co-authorship on competition paper</li>
                        <li>$500 additional GPU credits</li>
                        <li>Featured team spotlight</li>
                    </ul>
                </div>
            </div>
            <div class="additional-prizes">
                <h3>Additional Recognition</h3>
                <div class="recognition-grid">
                    <div class="recognition-item">
                        <h4>Top 10 Teams</h4>
                        <p>Certificate of Excellence and invitation to virtual presentation session</p>
                    </div>
                    <div class="recognition-item">
                        <h4>Best Novel Approach</h4>
                        <p>$51,000 special prize for most innovative data curation method</p>
                    </div>
                    <div class="recognition-item">
                        <h4>Student Teams</h4>
                        <p>Special recognition for best all-student team submission</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="quick-start" id="quick-start">
        <div class="container">
            <div class="section-title">
                <h2>üöÄ Quick Start</h2>
                <p>Get started with training in minutes</p>
            </div>
            <div class="quickstart-content">
                <pre class="code-block">
# install oumi
uv pip install "oumi[gpu]"

# train with Molmo-7B-O
oumi train -c molmo-o --dataset dataset.jsonl

# train with Qwen2.5-VL-7B-Instruct
oumi train -c qwen2.5-vl-7b-instruct --dataset dataset.jsonl
</pre>
            </div>
        </div>
    </section>

    <section class="technical-specs" id="technical-specs">
        <div class="container">
            <div class="section-title">
                <h2>Technical Specifications</h2>
                <p>Detailed requirements and specifications for the competition</p>
            </div>
            <div class="specs-grid">
                <div class="spec-card">
                    <h3>ü§ñ Model Architecture</h3>
                    <div class="spec-details">
                        <h4>Evaluation Model: Undisclosed 8B-class model</h4>
                        <ul>
                            <li>Final evaluation uses an undisclosed model</li>
                            <li>Participants get scripts for multiple models</li>
                            <li>Good curation strategies should generalize</li>
                            <li>Multi-modal transformer architectures</li>
                            <li>Various parameter sizes available for development</li>
                        </ul>
                    </div>
                </div>

                <div class="spec-card">
                    <h3>üìä Dataset Specifications</h3>
                    <div class="spec-details">
                        <h4>Dataset Flexibility</h4>
                        <ul>
                            <li>Use any datasets for curation</li>
                            <li>Starter kit provides examples and guidance</li>
                            <li>Support for various image formats and resolutions</li>
                            <li>Flexible text formats and lengths</li>
                            <li>Focus on instruction-tuning quality over quantity</li>
                        </ul>
                    </div>
                </div>
                <div class="spec-card">
                    <h3>üíª Hardware Requirements</h3>
                    <div class="spec-details">
                        <h4>Minimum Specifications</h4>
                        <ul>
                            <li>GPU: 1x NVIDIA A100-80GB or equivalent (4x GPUs recommended)</li>
                            <li>RAM: 64GB system memory</li>
                            <li>Storage: 500GB available space</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="submission-format" id="submission-format">
        <div class="container">
            <div class="section-title">
                <h2>Submission Format</h2>
                <p>How to structure and submit your curated datasets</p>
            </div>
            <div class="submission-container">
                <div class="submission-step">
                    <div class="step-number">1</div>
                    <h3>Dataset Structure</h3>
                    <p>Your submission must include:</p>
                    <pre class="code-block">
submission/
‚îú‚îÄ‚îÄ train_1k.jsonl|parquet  # or train_10k.jsonl|parquet
‚îú‚îÄ‚îÄ metadata.json           # Team and method info
‚îú‚îÄ‚îÄ technical_report.pdf    # 2-4 page report
‚îî‚îÄ‚îÄ README.md               # Instructions</pre>
                </div>
        <div class="submission-step">
            <div class="step-number">2</div>
            <h3>Data Format</h3>
            <p>Each training example must follow this format:</p>
            <pre class="code-block">
[
    {
        # binary image data for parquet, base64 for jsonl
        "image": "encoded_image", 
        "prompt": "What is shown in this image?",
        "response": "The image shows a cat."
    },
    ...
]
        </pre>

        </div>
            <div class="submission-step">
                <div class="step-number">3</div>
                <h3>Technical Report</h3>
                <p>Your report must include:</p>
                <ul>
                    <li>Data curation methodology</li>
                    <li>Selection criteria and rationale</li>
                    <li>Conversation generation approach</li>
                    <li>Computational resources used</li>
                    <li>Ablation studies (optional)</li>
                    <li>References and acknowledgments</li>
                </ul>
            </div>
        </div>
        </div>
    </section>


    <section class="teams" id="team">
        <div class="container">
            <div class="section-title">
                <h2>Organizing Team</h2>
            </div>
            <div class="team-grid">
                <div class="team-member">
                    <img src="static/images/benjamin_feuer.webp" alt="Professional headshot of Benjamin Feuer, Lead Organizer of the DCVLR competition from New York University (NYU)." aria-label="Benjamin Feuer's profile picture">
                    <h3><a href="https://penfever.github.io" target="_blank" rel="noopener">Benjamin Feuer</a></h3>
                    <p>Lead Organizer</p>
                    <p>NYU</p>
                </div>
                <div class="team-member">
                    <img src="static/images/rohun.jpg" alt="Professional headshot of Rohun Tripathi, Lead Organizer of the DCVLR competition from the Allen Institute for AI." aria-label="Rohun Tripathi's profile picture">
                    <h3><a href="https://rohun-tripathi.github.io/" target="_blank" rel="noopener">Rohun Tripathi</a></h3>
                    <p>Lead Organizer</p>
                    <p>Allen Institute for AI</p>
                </div>
                <div class="team-member">
                    <img src="static/images/oussama.webp" alt="Professional headshot of Oussama Elachqar, Lead Organizer of the DCVLR competition from Oumi." aria-label="Oussama Elachqar's profile picture">
                    <h3><a href="https://www.linkedin.com/in/oussamaelachqar/" target="_blank" rel="noopener">Oussama Elachqar</a></h3>
                    <p>Lead Organizer</p>
                    <p>Oumi</p>
                </div>
                <div class="team-member">
                    <img src="static/images/yuhui.jpeg" alt="Professional headshot of Yuhui Zhang, Lead Organizer of the DCVLR competition from Stanford University." aria-label="Yuhui Zhang's profile picture">
                    <h3><a href="https://cs.stanford.edu/~yuhuiz/" target="_blank" rel="noopener">Yuhui Zhang</a></h3>
                    <p>Lead Organizer</p>
                    <p>Stanford University</p>
                </div>
                <div class="team-member">
                    <img src="static/images/neha.png" alt="Professional headshot of Neha Hulkund, Lead Organizer of the DCVLR competition from Massachusetts Institute of Technology (MIT)." aria-label="Neha Hulkund's profile picture">
                    <h3><a href="https://hulkund.github.io" target="_blank" rel="noopener">Neha Hulkund</a></h3>
                    <p>Lead Organizer</p>
                    <p>MIT</p>
                </div>
                <div class="team-member">
                    <img src="static/images/thao.jpg" alt="Professional headshot of Thao Nguyen, Organizer of the DCVLR competition from the University of Washington." aria-label="Thao Nguyen's profile picture">
                    <h3><a href="https://thaonguyen19.github.io/" target="_blank" rel="noopener">Thao Nguyen</a></h3>
                    <p>Helping Organizer</p>
                    <p>University of Washington</p>
                </div>
                <div class="team-member">
                    <img src="static/images/nimrod.jpeg" alt="Professional headshot of Nimrod Shabtay, Organizer of the DCVLR competition from IBM Research." aria-label="Nimrod Shabtay's profile picture">
                    <h3><a href="https://www.linkedin.com/in/nimrod-shabtay/" target="_blank" rel="noopener">Nimrod Shabtay</a></h3>
                    <p>Organizer</p>
                    <p>Tel Aviv University & IBM Research</p>
                </div>
                <div class="team-member">
                     <img src="static/images/vishaal.jpeg" alt="Professional headshot of Vishaal Udandarao, Organizer of the DCVLR competition from The University of Tuebingen." aria-label="Vishaal Udandarao's profile picture">
                     <h3><a href="https://vishaal27.github.io" target="_blank" rel="noopener">Vishaal Udandarao</a></h3>
                     <p>Organizer</p>
                     <p>University of T√ºbingen</p>
                 </div>
                                 <div class="team-member">
                     <img src="static/images/xiaohan.jpg" alt="Professional headshot of Xiaohan Wang, Organizer of the DCVLR competition from Stanford University." aria-label="Xiaohan Wang's profile picture">
                     <h3><a href="https://wxh1996.github.io" target="_blank" rel="noopener">Xiaohan Wang</a></h3>
                     <p>Organizer</p>
                     <p>Stanford University</p>
                 </div>
                 <div class="team-member">
                    <img src="static/images/stefan_webb.webp" alt="Professional headshot of Stefan Webb, Organizer of the DCVLR competition from Oumi." aria-label="Stefan Webb's profile picture">
                    <h3><a href="https://www.linkedin.com/in/stefan-webb/" target="_blank" rel="noopener">Stefan Webb</a></h3>
                    <p>Organizer</p>
                    <p>Oumi</p>
                </div>
                <div class="team-member">
                     <img src="static/images/sara-beery.jpg" alt="Professional headshot of Sara Beery, Organizer of the DCVLR competition from MIT." aria-label="Sara Beery's profile picture">
                     <h3><a href="https://beerys.github.io/" target="_blank" rel="noopener">Sara Beery</a></h3>
                     <p>Organizer</p>
                     <p>MIT</p>
                 </div>
                <div class="team-member">
                     <img src="static/images/georgia_gkioxari.webp" alt="Professional headshot of Georgia Gkioxari, Organizer of the DCVLR competition from Caltech." aria-label="Georgia Gkioxari's profile picture">
                     <h3><a href="https://gkioxari.github.io" target="_blank" rel="noopener">Georgia Gkioxari</a></h3>
                     <p>Organizer</p>
                     <p>Caltech</p>
                 </div>
                 <div class="team-member">
                     <img src="static/images/manos.webp" alt="Professional headshot of Emmanouil Koukoumidis, Organizer of the DCVLR competition from Oumi." aria-label="Emmanouil Koukoumidis's profile picture">
                     <h3><a href="https://www.linkedin.com/in/koukoumidis" target="_blank" rel="noopener">Emmanouil (Manos) Koukoumidis</a></h3>
                     <p>Organizer</p>
                     <p>Oumi</p>
                 </div>
      
                <div class="team-member">
                     <img src="static/images/ludwig.jpg" alt="Professional headshot of Ludwig Schmidt, Organizer of the DCVLR competition from Stanford University." aria-label="Ludwig Schmidt's profile picture">
                     <h3><a href="https://people.csail.mit.edu/ludwigs/" target="_blank" rel="noopener">Ludwig Schmidt</a></h3>
                     <p>Organizer</p>
                     <p>Stanford University</p>
                 </div>
                <div class="team-member">
                     <img src="static/images/saining_xie.webp" alt="Professional headshot of Saining Xie, Organizer of the DCVLR competition from NYU." aria-label="Saining Xie's profile picture">
                     <h3><a href="https://www.sainingxie.com" target="_blank" rel="noopener">Saining Xie</a></h3>
                     <p>Organizer</p>
                     <p>NYU</p>
                 </div>
                <div class="team-member">
                     <img src="static/images/serena.jpg" alt="Professional headshot of Serena Yeung-Levy, Organizer of the DCVLR competition from Stanford University." aria-label="Serena Yeung-Levy's profile picture">
                     <h3><a href="https://ai.stanford.edu/~syyeung/" target="_blank" rel="noopener">Serena Yeung-Levy</a></h3>
                     <p>Organizer</p>
                     <p>Stanford University</p>
                 </div>
                 <div class="team-member">
                    <img src="static/images/paul_pu_liang.webp" alt="Professional headshot of Paul Liang, Organizer of the DCVLR competition from MIT." aria-label="Paul Liang's profile picture">
                    <h3><a href="https://pliang279.github.io" target="_blank" rel="noopener">Paul Liang</a></h3>
                    <p>Organizer</p>
                    <p>MIT</p>
                </div>
             </div>
        </div>
    </section>


    <section class="leaderboard-preview" id="leaderboard">
        <div class="container">
            <div class="section-title">
                <h2>Live Leaderboard</h2>
                <p>Baseline performance on <a href="https://yuhui-zh15.github.io/AutoConverter-Website/" target="_blank" rel="noopener">VMC-Bench</a> reasoning subset. The private competition benchmark will use different evaluation metrics and datasets to ensure fair evaluation.</p>
            </div>
            <div class="leaderboard-container">
                <div class="leaderboard-tabs">
                    <button class="tab-button active" data-track="1k">1K Track</button>
                    <button class="tab-button" data-track="10k">10K Track</button>
                </div>
                <div class="leaderboard-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Rank</th>
                                <th>Team</th>
                                <th>Score</th>
                                <th>Submissions</th>
                                <th>Last Update</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="top-3">
                                <td class="rank">1</td>
                                <td class="team-name">VisionCrafters</td>
                                <td class="score">92.4%</td>
                                <td>2/3</td>
                                <td>2 hours ago</td>
                            </tr>
                            <tr class="top-3">
                                <td class="rank">2</td>
                                <td class="team-name">DataAlchemists</td>
                                <td class="score">91.8%</td>
                                <td>3/3</td>
                                <td>5 hours ago</td>
                            </tr>
                            <tr class="top-3">
                                <td class="rank">3</td>
                                <td class="team-name">NeuralNavigators</td>
                                <td class="score">91.2%</td>
                                <td>1/3</td>
                                <td>1 day ago</td>
                            </tr>
                            <tr>
                                <td class="rank">4</td>
                                <td class="team-name">CurateAI</td>
                                <td class="score">90.5%</td>
                                <td>2/3</td>
                                <td>1 day ago</td>
                            </tr>
                            <tr>
                                <td class="rank">5</td>
                                <td class="team-name">VLM Masters</td>
                                <td class="score">89.9%</td>
                                <td>1/3</td>
                                <td>2 days ago</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <div class="leaderboard-note">
                    <p>The submission portal will open on July 1, 2025.</p>
                    <a href="#" class="cta-button">Sign up for updates</a>
                </div>
            </div>
        </div>
    </section>

    <section class="faq" id="faq">
        <div class="container">
            <div class="section-title">
                <h2>Frequently Asked Questions</h2>
                <p>Common questions about the DCVLR competition</p>
            </div>
            <div class="faq-container">
                <div class="faq-item">
                    <h3>What is the goal of this competition?</h3>
                    <div class="faq-answer">
                        <p>The goal is to advance the visual reasoning capabilities of vision-language models through instruction-tuning dataset curation. By isolating data as the primary variable, we aim to understand what data properties catalyze reasoning capabilities in neural systems.</p>
                    </div>
                </div>
                <div class="faq-item">
                    <h3>Who can participate?</h3>
                    <div class="faq-answer">
                        <p>The competition is open to everyone, from students and academic researchers to industry professionals. We especially encourage participation from diverse backgrounds and institutions.</p>
                    </div>
                </div>
                <div class="faq-item">
                    <h3>What computational resources do I need?</h3>
                    <div class="faq-answer">
                        <p>Fine-tuning and evaluation can be done on a single GPU. We provide GPU credits from Lambda Labs for a limited number of participants to ensure accessibility.</p>
                    </div>
                </div>
                <div class="faq-item">
                    <h3>How will submissions be evaluated?</h3>
                    <div class="faq-answer">
                        <p>Submissions will be evaluated by fine-tuning an undisclosed vision-language model on the curated data and measuring performance across a wide variety of benchmarks. This approach tests whether good data curation strategies generalize across different models and evaluation settings.</p>
                    </div>
                </div>
                <div class="faq-item">
                    <h3>Can I use external data or models?</h3>
                    <div class="faq-answer">
                        <p>You can use any datasets you want for data curation. We provide a comprehensive starter kit to help you get started, and you may use external tools (e.g., LLMs) to synthesize instruction-tuning examples. The key constraint is no manual annotation.</p>
                    </div>
                </div>
                <div class="faq-item">
                    <h3>Are there any prizes?</h3>
                    <div class="faq-answer">
                        <p>Yes! Total prize pool of $25,000 USD. First place: $10,000, Second place: $7,500, Third place: $5,000. Winners also receive podium presentations at <a href="https://neurips.cc/" target="_blank" rel="noopener">NeurIPS</a>, invitation to co-author a joint system paper, and additional GPU credits. Top 10 teams receive recognition certificates.</p>
                    </div>
                </div>
                <div class="faq-item">
                    <h3>How many submissions can I make?</h3>
                    <div class="faq-answer">
                        <p>Each team may submit up to 3 final versions. The highest-scoring submission will be used for ranking.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="sponsors" id="sponsors">
        <div class="container">
            <div class="section-title">
                <h2>Competition Sponsors</h2>
            </div>
            <div class="sponsors-logos">
                <a href="https://lambda.ai" target="_blank" rel="noopener" class="sponsor-logo-link">
                    <img src="static/images/lambda-labs-logo.svg" alt="Lambda Labs" class="sponsor-logo">
                </a>
                <a href="https://oumi.ai" target="_blank" rel="noopener" class="sponsor-logo-link">
                    <img src="static/images/oumi_logo_dark.png" alt="Oumi.ai" class="sponsor-logo">
                </a>
            </div>
        </div>
    </section>

    <section class="contact" id="contact">
        <div class="container">
            <div class="section-title">
                <h2>Contact Us</h2>
                <p>Have questions? Get in touch with the DCVLR team</p>
            </div>
            <div class="contact-icons">
                <a href="mailto:dcvlr_neurips@googlegroups.com" class="contact-icon email" aria-label="Email us">
                    <svg width="32" height="32" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/>
                    </svg>
                </a>
                <a href="https://github.com/oumi-ai/oumi/tree/main/configs/projects" target="_blank" rel="noopener" class="contact-icon github" aria-label="GitHub Repository">
                    <svg width="32" height="32" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                    </svg>
                </a>
                <a href="https://twitter.com/DCVLR_NeurIPS" target="_blank" rel="noopener" class="contact-icon twitter" aria-label="Twitter">
                    <svg width="32" height="32" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
                    </svg>
                </a>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <div class="social-share">
                <p>Share this competition:</p>
                <div class="share-buttons">
                    <a href="https://twitter.com/intent/tweet?text=Join%20the%20DCVLR%20NeurIPS%202025%20Competition!%20Advance%20visual%20reasoning%20in%20VLMs%20through%20data%20curation.&url=https://dcvlr-neurips.github.io/dcvlr-neurips/" target="_blank" rel="noopener" class="share-button twitter" aria-label="Share on Twitter" onclick="trackSocialShare('twitter')">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
                    </a>
                    <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://dcvlr-neurips.github.io/dcvlr-neurips/" target="_blank" rel="noopener" class="share-button linkedin" aria-label="Share on LinkedIn" onclick="trackSocialShare('linkedin')">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                    </a>
                    <a href="mailto:?subject=DCVLR%20NeurIPS%202025%20Competition&body=Check%20out%20this%20exciting%20competition%20on%20data%20curation%20for%20vision-language%20reasoning:%20https://dcvlr-neurips.github.io/dcvlr-neurips/" class="share-button email" aria-label="Share via Email" onclick="trackSocialShare('email')">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor"><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"/></svg>
                    </a>
                </div>
            </div>
        </div>
    </footer>

    <script src="static/js/app.js"></script>
    </div>
</body>
</html>